{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d0dfb6-e85c-4282-951f-0fc182c4a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.winnet.lifting import RevNetLiftingPair\n",
    "from models.winnet.splitmerge import DCTSplitMerge, HaarSplitMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1af7d8a-68a9-4860-b525-f078de691044",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, H, W = 8, 32, 32\n",
    "x = torch.randn(B, 3, H, W)\n",
    "sigma = torch.zeros(B, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bd04f7-7cde-4758-9546-6a6eaff93339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 16, 16]) torch.Size([8, 9, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "haar_sm = HaarSplitMerge()\n",
    "\n",
    "c, d = haar_sm(x)\n",
    "print(c.shape, d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d971893-7095-41ea-a89c-35336377902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_merge = DCTSplitMerge(\n",
    "    in_channels=3,\n",
    "    coarse_to_in_ch_ratio=1,\n",
    "    patch_size=5,\n",
    ")\n",
    "\n",
    "revnet_lift = RevNetLiftingPair(\n",
    "    coarse_ch=3, \n",
    "    detail_ch=72, \n",
    "    hidden_ch=96,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a138aa9-8f0c-4bf9-a21f-0b6a5bf8be8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 32, 32]) torch.Size([8, 72, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "c, d = split_merge.forward(x)\n",
    "print(c.shape, d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea055c3-3a1c-465c-b470-26a85775329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 32, 32]) torch.Size([8, 72, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "c, d = revnet_lift(c, d, sigma)\n",
    "print(c.shape, d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d944c77e-f310-4f0f-a3f9-428d4abe91b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.7661, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "c, d = revnet_lift.inverse(c, d, sigma)\n",
    "x_rec  = split_merge.inverse(c, d)\n",
    "\n",
    "print((x - x_rec).abs().max())            # â‰ˆ 1e-6 (floating-point noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f886a07-ac61-4d19-9e1b-b39273139a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcdb9d94-f46a-43d5-bed7-065b688d8d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lifting_denoiser import LiftingDenoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33b1a3f8-d475-41db-8840-f3b354c8a3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_channels: 1\n",
      "coarse_channels: 3\n",
      "hidden_channels: 128\n",
      "num_lifting_steps: 4\n",
      "lifting_type: revnet\n",
      "detail_denoiser: clista\n",
      "split_merge_type: haar_redundant\n",
      "do_convert_t_to_sigma: True\n",
      "num_haar_scales: 4\n",
      "latent_channels: 128\n"
     ]
    }
   ],
   "source": [
    "# new LiftingDenoiser init params\n",
    "\n",
    "unet_params = {\n",
    "    \"base_channels\": 16,\n",
    "    \"channel_multipliers\": (1, 2, 4, 8),\n",
    "}\n",
    "\n",
    "clista_params = {\n",
    "    \"latent_channels\": 128,\n",
    "}\n",
    "\n",
    "init_params = {\n",
    "    \"input_channels\": 1,\n",
    "    \"coarse_channels\": 3,\n",
    "    \"hidden_channels\": 128,\n",
    "    \"num_lifting_steps\": 4,\n",
    "    \"lifting_type\": \"revnet\",\n",
    "    \"detail_denoiser\": \"clista\",\n",
    "    \"split_merge_type\": \"haar_redundant\",\n",
    "    \"do_convert_t_to_sigma\": True,\n",
    "    \"num_haar_scales\": 4,\n",
    "}\n",
    "\n",
    "if init_params[\"detail_denoiser\"] == \"unet\":\n",
    "    init_params.update(unet_params)\n",
    "elif init_params[\"detail_denoiser\"] == \"clista\":\n",
    "    init_params.update(clista_params)\n",
    "    \n",
    "for key, val in init_params.items():\n",
    "    print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b5277e0-cda3-479b-8884-eb342a312552",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LiftingDenoiser(\n",
    "    **init_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcaea502-1294-4f59-8b78-8bbddb197cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1616032"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92f172da-833a-425a-ab62-0147a1b394b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coarse_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ec28cd8-cdd2-4c7b-8501-8bde371ea2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.detail_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "410c617b-658a-4bdc-b3a5-a27b10e61b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LiftingDenoiser(\n",
       "  (split_merge): MultiScaleStationaryHaar()\n",
       "  (lifting_steps): ModuleList(\n",
       "    (0-3): 4 x RevNetLiftingPair(\n",
       "      (f): Conditioner(\n",
       "        (b1): ConvFiLMBlock(\n",
       "          (conv): Conv2d(10, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (gn): GroupNorm(8, 128, eps=1e-05, affine=False)\n",
       "          (film): FiLM(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (b2): ConvFiLMBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (gn): GroupNorm(8, 128, eps=1e-05, affine=False)\n",
       "          (film): FiLM(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (b3): ConvFiLMBlock(\n",
       "          (conv): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (gn): GroupNorm(3, 3, eps=1e-05, affine=False)\n",
       "          (film): FiLM(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (g): Conditioner(\n",
       "        (b1): ConvFiLMBlock(\n",
       "          (conv): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (gn): GroupNorm(8, 128, eps=1e-05, affine=False)\n",
       "          (film): FiLM(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (b2): ConvFiLMBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (gn): GroupNorm(8, 128, eps=1e-05, affine=False)\n",
       "          (film): FiLM(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (b3): ConvFiLMBlock(\n",
       "          (conv): Conv2d(128, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (gn): GroupNorm(10, 10, eps=1e-05, affine=False)\n",
       "          (film): FiLM(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=20, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (detail_denoiser): CLISTADenoise(\n",
       "    (soft_thresholds): ModuleList(\n",
       "      (0-2): 3 x SoftThresholdActivation(\n",
       "        (_softplus): Softplus(beta=20.0, threshold=20.0)\n",
       "      )\n",
       "    )\n",
       "    (analysis_conv): SiLUResBlock(\n",
       "      (conv1): Conv2d(10, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (skip): Conv2d(10, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (synthesis_conv): SiLUResBlock(\n",
       "      (conv1): Conv2d(128, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (skip): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a02da06-a8d6-4750-abae-693f1d5a79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, H, W = 8, 32, 32\n",
    "x = torch.randn(B, 1, H, W)\n",
    "t = torch.zeros(B, dtype=torch.long)\n",
    "sigma = torch.zeros(B, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c126968c-c291-4c17-833b-f8b94a0af3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated sigma values.\n"
     ]
    }
   ],
   "source": [
    "model.update_sigmas_t(sigma, \"Successfully updated sigma values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be277fd0-412a-4f99-969c-793d3005e095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 32, 32])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(x, t)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5a5df-96e1-42aa-8500-50c754d83976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c531ec4-3f7e-4701-a54c-b798c3fa5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.winnet.splitmerge import StationaryHaarSplitMerge\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53690b29-8707-4bf3-bfea-2f2caf877521",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StationaryHaarSplitMerge.__init__() got an unexpected keyword argument 'coarse_to_in_ch_ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stationary_haar_sm \u001b[38;5;241m=\u001b[39m StationaryHaarSplitMerge(\n\u001b[0;32m      2\u001b[0m     coarse_to_in_ch_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m      3\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: StationaryHaarSplitMerge.__init__() got an unexpected keyword argument 'coarse_to_in_ch_ratio'"
     ]
    }
   ],
   "source": [
    "stationary_haar_sm = StationaryHaarSplitMerge(\n",
    "    coarse_to_in_ch_ratio=1, \n",
    "    in_channels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac3db2-2c62-4817-83c6-63ce56bf65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, H, W = 8, 32, 32\n",
    "x = torch.randn(B, 3, H, W)\n",
    "sigma = torch.zeros(B, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f0eac-ff19-4535-9610-598b71c93bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, d = stationary_haar_sm(x)\n",
    "print(c.shape, d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158891ef-3f04-4b76-a1cf-66b7af243cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515b00c-f871-406a-8e80-ec2d6504c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    channel_multipliers=(1, 2, 4, 4),\n",
    "    base_channels=256,\n",
    "    # attention_heads=8,\n",
    "    # attention_head_dim=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf125b-382f-46cb-a854-017455c8e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "print(f\"no. of parameters: {param_count // 1e6} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1dee7-f8b2-4ef1-84da-287ec25a1338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
