{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdadc111-f540-4dc9-bcd0-354a1a80ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c3e3fa-45ce-4732-ad12-75ce4a2af507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils_path = os.path.join(os.getcwd(), \"winnet\")\n",
    "# utils_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241f0755-cb77-42b5-bff1-3afb48abf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(utils_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b1ba88-cef4-43f9-8226-f330a9e4a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import UNet\n",
    "from models.lifting_denoiser import LiftingDenoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95383962-a598-4180-970a-eaa33af50429",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = {\n",
    "    \"UNet\": {\n",
    "        \"base_channels\": 16,\n",
    "        \"channel_multipliers\": (1, 2, 4, 8),\n",
    "        \"in_channels\": 3 # 1 for Fashion-MNIST, 3 for CIFAR-10\n",
    "    },\n",
    "    \"LiftingDenoiser\": {\n",
    "        \"input_channels\": 3,\n",
    "        \"coarse_channels\": 3,\n",
    "        \"hidden_channels\": 128,\n",
    "        \"num_lifting_steps\": 4,\n",
    "        \"lifting_type\": \"revnet\",\n",
    "        \"detail_denoiser\": \"clista\",\n",
    "        \"split_merge_type\": \"haar_redundant\",\n",
    "        \"do_convert_t_to_sigma\": True,\n",
    "        # \"split_merge_patch_size\": 4,\n",
    "    },\n",
    "    \"GaussianDiffusion\": {\n",
    "        \"image_size\": 32, # 28 for raw Fashion-MNIST, 32 after padding/resize\n",
    "        \"timesteps\": 1000, # forward diffusion steps\n",
    "        \"sampling_timesteps\": 10, # DDIM steps at inference\n",
    "        \"objective\": \"pred_x0\" # or 'pred_noise' or 'pred_v'\n",
    "    },\n",
    "    \"Trainer\": {\n",
    "        \"folder\": './cifar_images',\n",
    "        \"results_folder\": './results',\n",
    "        \"train_batch_size\": 128,\n",
    "        \"train_lr\": 1e-6,\n",
    "        \"train_num_steps\": 2,\n",
    "        \"ema_update_every\": 10,\n",
    "        \"num_samples\": 4, \n",
    "        \"calculate_fid\": True, \n",
    "        \"amp\": True,\n",
    "        \"save_and_sample_every\": 1,\n",
    "        \"save_best_and_latest_only\": True,\n",
    "        \"lr_scheduler_type\":\"cosine\",        # or \"step\", \"exponential\", \"lambda\", None\n",
    "        \"lr_scheduler_kwargs\": {\"eta_min\": 1e-7},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef1209a-344f-4974-8932-2f704ee4c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_unet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1a5a5b-9efb-43dd-9457-c2217927514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_unet:\n",
    "    model = UNet(**init_params[\"UNet\"])\n",
    "else:\n",
    "    model = LiftingDenoiser(**init_params[\"LiftingDenoiser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40c7c4a-4e17-4ff1-9a8d-d1566c463d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1481513"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b83b284-a440-4572-9ec6-b94f30ad59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.diffusion import GaussianDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39cbdbb3-1d3e-49ec-8e64-3548968352c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated `sigmas` tensor successfully.\n"
     ]
    }
   ],
   "source": [
    "diffusion_model = GaussianDiffusion(\n",
    "    model,\n",
    "    **init_params[\"GaussianDiffusion\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676f2c7-8ea5-4b45-b33e-660dc2964b18",
   "metadata": {},
   "source": [
    "The cell below only needs to be run once; subsequent runs will use the downloaded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796f4f10-89ec-48f3-8c1b-b4d038c7153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root      = './data'\n",
    "save_root = Path('./fashion_images')\n",
    "save_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fm_train = datasets.FashionMNIST(\n",
    "    root, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    ])\n",
    "        \n",
    ")\n",
    "for idx, (tensor, _) in enumerate(fm_train):\n",
    "    # convert 0-1 tensor → PIL L and (optionally) pad to 32×32\n",
    "    img = transforms.ToPILImage(mode='RGB')(tensor)\n",
    "    img = transforms.Resize(32, antialias=True)(img)   # keep square, upsample\n",
    "    img.save(save_root / f'{idx:06}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0832d11-bfb5-49dd-9128-d50c3a4ee671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root      = './data'\n",
    "# save_root = Path('./cifar_images')\n",
    "# save_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# cifar_train = datasets.CIFAR10(root, train=True, download=True)\n",
    "# for idx, (img, _) in enumerate(cifar_train):\n",
    "#     img.save(save_root / f'{idx:06}.png')   # already 32×32 RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8064a713-f303-4641-96f3-0e1c94b27c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.trainer import DiffusionTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a043fcc9-1400-4774-8918-808bce898384",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_trainer = DiffusionTrainer(\n",
    "    diffusion_model,\n",
    "    **init_params[\"Trainer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2350cfac-854a-4bd1-9477-adc8efeeae4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e68d87404943289ff827fa21e6e5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89873ca98ad54c9eb0d587386a18eab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Inception features for 50000 samples from the real dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb864bc7ae64612af6e7d2bd441ad0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diffusion_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82338165-e4c8-4c51-9321-c1380cf072ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
